\documentclass[11pt]{article} % use larger type; default would be 10pt
\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)
\usepackage{geometry} % to change the page dimensions
\geometry{letterpaper} 
\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\usepackage{sectsty}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{array}
 \usepackage{parskip}

\numberwithin{equation}{section}

\title{\huge \textbf{1859 CE and beyond: Some reflections}}
\author{}
\date{}

\begin{document}
\maketitle
The junction of the yuga between 1800 CE and 1900 CE saw a remarkable change in our understanding of the world at many levels. It is not that some of these ideas did not exist long before that time but they came together in a world-system of science and philosophy in that period. Part of this change can be traced to multiple disparate events that interestingly happened in the year 1859 CE -- a time when our nation had sunk to what was perhaps the lowest points of its existence. Due that our nation could not fully participate in the cataclysmic consequences of those events until some time later and the Hindu elite have still not fully internalized the significance of those events. 

\section{The Big}
The mathematical foundations of mechanics laid by Newton with deep roots in Euclidean geometry had met with near infallible success. The physicists drunk with confidence of the triumph of Newton believed that they could account for all physical phenomena based on that mathematical formulation. But it was ironically this very mathematical formulation that was to point that something was amiss: The great Carl Causs had shown how with just three observations one could calculate the orbit of a celestial body and used this recover the asteroid Ceres which had been lost after going behind the sun. Gauss’s student was Johann  Encke, who a few years after his graduation developed methods to calculate the perturbational effects of various celestial bodies on the orbits of other such bodies. It was these methods that led to his discovering the period of a comet that latter came to be known as the famed Encke’ Comet and his other great works on cometary orbits.\\

Following on the path of Encke’s methods, the great French mathematician Urbain Le Verrier came to be “the man who discovered a planet with the point of his pen” as his colleague called him. By performing complex and painstaking calculations of Newtonian mechanics he showed that the orbit of Uranus could not be explained by the known data and proposed a new planet to explain it. Not just that, he predicted where that planet would be in the sky pointing to a location at the boundary of Capricornus and Aquarius. With no Frenchmen showing interest in testing his prediction, he sent his predictions over to Encke at Berlin. But the day Encke received Le Verrier’s letter was his birthday and he had organized big party for the evening rather than an observation session. Moreover, he was much more of a man of mathematics than an observer. By some coincidence, he had recently had his former doctoral student Carl Bremiker make excellent new star maps of the Aquarius-Capricornus region for the observatory. Further, Encke’s assistant and former student Johann Galle had sent his doctoral dissertation to Le Verrier for comments and this letter from Le Verrier contained the comments on that in addition to his note on the prediction of a new planet. Thus, with Encke not observing, Johann Galle and his student Heinrich d'Arrest got to use the telescope that night of receiving the Le Verrier’s letter. They discovered Neptune with $1^o$ degree of the position he had predicted. When we saw Neptune for the first time after quite some difficulty with our small refractor, we were able to appreciate the triumph of Galle. This was the ultimate triumph of Newtonian mechanics and Encke fittingly wrote to Le Verrier: “Your name will be forever linked with the most outstanding conceivable proof of the validity of universal gravitation.” By this Encke meant the Newtonian theory of gravitation.\\

But there was something ironic about Le Verrier’s life’s work. Before his study of Uranus leading the prediction Neptune, he had worked on the other end of solar system, where the elusive Mercury orbits, which these days the ordinary urban man rarely catches a glimpse of (I remember all the times I’ve seen it). Going through calculations involving hundreds of  terms he calculated an excess of  precession for the orbit of Mercury which could not be accounted for by Newtonian mechanics (September $12^{th}$ 1859).  While the same trick of postulating an additional planet or other anomalies were tried, none of them really worked. Ironically the universality of Newtonian gravitation, which Encke thought Le Verrier had proven, now stood to be surpassed. This of course took a while to happen but seeds had been sowed by the new geometry of Bernhard Riemann. This laid the foundation for Einstein’s theory which came in the next century. At the same time as solving the excess precession problem of Mercury, Einstein as also predicted the existence of gravitational waves. Observations of binary pulsars in 1974 indirectly suggested he was right. With the detection of gravitational waves in the current century of the common era this prediction of Einstein has finally received its direct confirmation. Thus, one of the pillars of physics in the realm of the “big” was established.\\

[As an aside, talking of Riemann 1859 was also the year he published his famous paper establishing the relationship between the zeroes of the $\zeta$ function in the complex plane and its relationship to the distribution of the prime numbers.]

\section{The Small}
The 21 year old Gustav Kirchhoff, while still a student, discovered his famous laws of electrical circuits, which any student who has studied elementary high-school physics would have encountered. This was just the beginning of what was to be a remarkable career spanning multiple branches of science and mathematics. Continuing with his electrical work he showed that in resistance-less wire the electricity would flow at the speed of light. This important result formed the bed-rock of electromagnetism that was taken to conclusion JC Maxwell. He then worked with Robert Bunsen to develop spectroscopy and it was as part of this work that in October of 1859 CE that he reported  his observations on how the D-lines in the solar spectrum are further darkened when passed through a Bunsen burner flame with sodium. These observations culminated in Kirchhoff’s famous spectroscopic laws:\\
1) An incandescent solid, or a liquid or a gas under high pressure produces a continuous spectrum, i.e. like a rainbow of colors.\\
2) A gas under low pressure produces an emission spectrum, i.e. one with bright-lines of specific frequency.\\
3) A continuous spectrum when viewed through a cooler low-density gas produces an absorption spectrum, i.e dark lines are seen superimposed on the continuous spectrum.  These correspond to the bright lines produced when the same substance is heated and producing an emission spectrum.\\

The frequency $\nu$ at which the absorption or emission lines are seen depends on the substances emitting or absorbing light and the temperature to which they are heated. Further, by the end of 1859, using a rather elementary device of the below thought experiment Kirchhoff arrived at a basic theorem for the continuous spectrum:\\

Figure 1\\

Let $P_1$ and $P_2$ be 2 isolated, infinite, opaque (do not allow transmission energy through them) plates (as caricatured in Figure 1) in thermodynamic equilibrium, i.e. they are at the same absolute temperature $T$ and the inflow of energy and outflow of energy into either plate is in balance. Let us even assume they are made of different materials as indicated by the different colors in Figure 1 different. Let us consider the following for a particular frequency of radiation $\nu$.  Let $a_1, a_2$ be the absorptivity of the 2 plates, i.e. the amount of radiant energy absorbed per unit time per unit area. Let $e_1, e_2$ be the emissivity of the 2 plates, i.e. the amount of energy they radiate per unit time per unit area. Now the some of the energy incident on them is absorbed while the rest is reflected. This defines the respective reflectivities as $r_1=1-a_1, r_2=1-a_2$. Now, for $P_1$ the outflow of energy per unit time per unit area is $e_1$. Being in thermodynamic equilibrium it is in balance with its inflow $\iota_1$.\\ 

Now we can analyze $\iota_1$ thus:\\ 
1) As the first chain of inflow $P_1$ receives $e_2$ from $P_2$. Of this it absorbs $a_1 e_2$ (the first order absorption) and reflects $r_1 e_2$. This is incident on $P_2$ which reflects back $r_1 e_2 r_2$. Of this $P_1$ absorbs $a_1 e_2 r_1 r_2$ (second order absorption) and reflects back $e_2 r_1^2 r_2$. In turn $P_2$ reflects back $e_2 (r_1 r_2)^2$ of which $P_1$ absorbs $a_1 e_2 (r_1 r_2)^2$. $P_1$ reflects back $e_2 r_1^3r_2^2$ and the chain continues \textit{ad infinitum}. Thus, we can write the first component of $\iota_1$ as:\\

 $a_1 e_2+a_1 e_2 r_1 r_2+ a_1 e_2 (r_1 r_2)^2+a_1 e_2 (r_1 r_2)^3+...\\[5pt]
 =a_1 e_2(1+r_1 r_2+ (r_1 r_2)^2+(r_1 r_2)^3+...)\\[5pt]
 =\dfrac{a_1 e_2}{1-r_1 r_2}$\\

The last step is obtained via the limit of the infinite sum of a geometric series given that $0 \le r_1 r_2<1$\\

2) The second chain of inflow goes thus: $P_1$ emits $e_1$ of which $P_2$ reflects back $e_1 r_2$. Of this $P_1$ absorbs $a_1 e_1 r_2$ and reflects back $e_1 r_1 r_2$. Of this $P_2$ reflects back $e_1 r_1 r_2^2$. Of this $P_1$ absorbs $a_1 e_1 r_1 r_2^2$ and reflects back $e_1 (r_1 r_2)^2$. Of this $P_2$ reflects back $e_1 r_1^2 r_2^3$. Thus, we can write the second component of $\iota_1$:\\

 $a_1 e_1 r_2+a_1 e_1 r_1 r_2^2+ a_1 e_1 r_1^2 r_2^3+...\\[5pt]
  =a_1 e_1 r_2(1+r_1 r_2+ (r_1 r_2)^2+(r_1 r_2)^3+...) \\[5pt]
  =\dfrac{a_1 e_1 r_2}{1-r_1 r_2}\\ [5pt]
  \therefore \iota_1 = \dfrac{a_1 e_2}{1-r_1 r_2} +\dfrac{a_1 e_1 r_2}{1-r_1 r_2}  = \dfrac{a_1 e_2+a_1 e_1 r_2}{1-r_1 r_2}$\\
 
Given the thermodynamic equilibrium $e_1 = \iota_1$; hence,\\
 
  $e_1=  \dfrac{a_1 e_2+a_1 e_1 r_2}{1-r_1 r_2}$\\

We can rearrange the equation as:\\
 $(1-r_1 r_2-a_1 r_2) e_1=a_1 e_2$\\

Dividing both sides by $a_1 a_2$ we get:\\
 $\dfrac{1-r_1 r_2 -a_1 r_2}{a_2} \left (\dfrac{e_1}{a_1} \right) = \dfrac{e_2}{a_2}$\\

Given that $r_1=1-a_1$ and  $r_2=1-a_2$ we can hence write the above as:\\

  $\dfrac{1-r_1 r_2 -((1 -r_1) r_2)}{1-r_2} \left (\dfrac{e_1}{a_1} \right) = \dfrac{e_2}{a_2} \\[5pt]
 \therefore \dfrac{e_1}{a_1}  = \dfrac{e_2}{a_2}$\\

Similarly, from $P_2$ we can write:\\

 $e_2=  \dfrac{a_2 e_1+a_2 e_2 r_1}{1-r_1 r_2}\\[5pt]
 \therefore \dfrac{1-r_1 r_2 -a_2 r_1}{a_1} \left (\dfrac{e_2}{a_2} \right)=\dfrac{e_1}{a_1}\\[5pt] 
 \therefore \dfrac{e_2}{a_2}  = \dfrac{e_1}{a_1}$\\
 
 Thus, irrespective of the material composition of the plates, their ratios of emissivity to absorptivity are the same. Since this analysis was done for a given frequency of radiation $\nu = \tfrac{1}{\lambda}$ (where $\lambda$ is the wavelength of the radiation) at a certain equilibrium temperature $T$, we can say that the above ratios are function of these:\\
 $\dfrac{e_2}{a_2}  = \dfrac{e_1}{a_1}= f(\nu, T)$\\

Now Kirchhoff postulated a theoretical body, termed the black body, that absorbed all energy incident on it, i.e. $a_1=a_2=a_b=1$. Thus, for such a black body the emissivity would be $e_b=f(\nu, T)$, i.e. it would be purely a function of the frequency of the radiation and its temperature. This immediately presented the physicists of the age with two challenges: 1) An experimental one, i.e. to construct a radiating body that approximates the black body as closely as possible and to empirically measure the shape of $f(\nu, T)$. 2) A theoretical one, i.e. to derive from a theoretical model of radiation the shape of $f(\nu, T)$ from what physics had to offer.\\

These challenges proved more revolutionary than physicists of the time thought. In 1869 CE one of the greatest physical theorists of all times, Ludwig Boltzmann, was appointed full professor of mathematical physics at the age of 25. Starting that year for the next two years he spent some time studying with Bunsen and Kirchhoff whose findings we have just alluded to. Deeply inspired by the discussions with them on thermodynamics, he went on to provide a statistical framework to explain the second law of thermodynamics in 1872 CE. Most European physicists of that time, unlike the chemists, did not consider the atomic theory to be real. Boltzmann not only considered atoms to be real (spherical atoms formed the foundation of his work on the second law) but in this work he introduced the idea of discrete energy levels. Later to the shock of the attending physicists in 1891 CE at a conference in Halle, Boltzmann emphatically stated: “I see no reason why energy shouldn’t also be regarded as divided atomically.” It was these ideas that were to provide the ultimate solution to Kirchhoff’s challenge.\\

On the experimental side it took about 20 years for the first glimmer of understanding to emerge with regard to $f(\nu, T)$, namely that it has one clear maximum when plotted against $\nu$, which moves to lower $\nu$ with decreasing T. Finally, in 1896 CE, Hermann von Helmholtz’s student, Wilhelm Wien, proposed the first reasonable function to account for this shape. It took the form $f(\nu, T)=a\nu^3e^{-b\nu/T}$, where $a, b$ are constants. In terms of its basic shape it resembled what was empirically known for $f(\nu, T)$ and the experiments by Paschen around that time suggested that indeed Wien had found the right curve for the black body radiation. However, new and more precise experiments at lower frequencies soon poured water on this. These experiments were being done by the groups of Lummer and Pringsheim on one hand and Rubens and Kurlbaum on the other at what where probably the best experimental physics labs in world at the dawn of the 1900s. They indicated that the function of Wien failed at lower frequencies.\\

The final solution to the problem came from the dark horse among the physicists, Max Planck, who had fittingly taken the professorial chair of Kirchhoff upon his death. This chair at Berlin was first offered to Boltzmann, who declined it; with no one taking it, finally it was given to Planck. He had a solid background having studied physics with Kirchhoff and von Helmholtz and mathematics under Weierstrass, who was second in line of academic descent from Gauss. Till the age of 40 he had done competent work in thermodynamics but was most part ‘scooped’ by the great American mathematician and inventor Josiah Gibbs, whose work in turn paralleled that of Boltzmann to enter the textbooks. Despite all this, Planck had for long set his mind on the bigger goal of deriving the correct shape of the black body radiation curve. Ironically, throughout most of this phase Planck was in the “wrong team”, opposing the atomic theory. As of 1897, Planck was still disputing the statistical framework of Boltzmann based on atomic principles. In response, Boltzmann published a paper showing that Planck’s objections were untenable and wrote that: “It is certainly possible and would be gratifying to derive for radiation phenomena a theorem analogously to the entropy theorem from the general laws for these phenomena using the same principles as in gas theory. Thus, I would be pleased, if the work of Dr. Planck on the scattering of electrical plane waves by very small resonators would become useful in this respect, which by the way are very simple calculations whose correctness I have never put in doubt.”\\

This rebuttal of Boltzmann brought about the gradual conversion of Planck over the next 3 years. His long-standing wish came to fruition fatefully on a Sunday afternoon in the autumn of 1900 when the family of Rubens who had done the black body radiation experiments visited the family of Planck. Rubens told his host about his latest experimental results with respect to the black body radiation measured for low frequencies and its departure from Wien’s proposal. That very evening Planck drawing on his deep study of Kirchhoffs fundamental problem arrived at correct formula for the black body radiation function:\\
 $f(\nu, T)=\dfrac{a\nu^3}{e^{-b\nu/T}-1}$, where $a,b$ are constants.\\

Figure 2. The form of Wien and Planck’s curves\\

Over the next two months, backed by his deep knowledge of thermodynamics, his strong mathematical capacity, the “conversion” he had undergone due to Boltzmann and the inspiration from those very methods of Boltzmann he arrived at the quantum theory where energy is emitted and absorbed in “atomic” packets or quanta. The energy $E$ of these quanta is described as $E=h\nu$, where $h$ is Planck’s constant. In the following years its power was demonstrated by Einstein who explained the photoelectric effect using the same theory. Thereafter, Niels Bohr used the same in combination with inspiration from Darwin’s grandson’s studies to arrive at the first quantum model of the atom. The rest as they say is history.\\

When my father first read out a basic version of this story to me when I was a kid I was profoundly inspired to study the quantum theory to the extent my meager mathematics allowed me when I grew older.
 
\section{Order and disorder}
In the late 400s and the beginning of the 500s of the common era the great Hindu scientist Āryabhaṭa-I devised several mechanical devices, which were powered by gravity and/or flowing water. One of these was the svayamvaha-yantra in which the water flowing out of a water clock under gravity caused a sphere to rotate around its axis once in 24 hours. This was meant as a teaching device to illustrate the apparent rotation of the heavenly sphere. Over hundred years later, in 628 CE, Āryabhaṭa’s successor and antagonist Brahmagupta, apparently in a bid to outdo him, claimed to have devised a svayamvaha-yantra which was a perpetual motion machine (ajasra-yantra). It was supposed to operate with gravity acting on mercury and buoyancy alternately working to keep a spoked wheel moving for ever. Evidently, this device did not work as expected prompting his successors, like Lalla and Bhāskara-II, to attempt various modifications and alternate designs to arrive at something which worked. While the real goal was obviously not attained, in India these failed attempts were part of a tradition of constructing genuinely working mechanical devices culminating in king Bhojadeva’s automata -- a tradition which did not survive the ravages of Mohammedanism. However, its transmission to West Asia appears to have seeded the quest for perpetual motion machines in Europe upon transmission of these ideas via the Mohammedans.\\

While from today’s vantage point the quest for these machines might look like sign of lunacy, the ultimate realization that perpetual motion machines are untenable culminated in the recognition of the laws of thermodynamics. This had to wait for long time and arose from meditations ensuing from the eventual invention of the steam engine in Europe. First, the Englishman Joule’s recognition that work and heat were manifestations of an equivalent quantity, i.e. energy, led to the first law of thermodynamics. This law is essentially the law of conservation of energy: \textit{energy can neither be created nor destroyed but only converted from one form to another}. This law negated the possibility of having a perpetual motion machine that did work without an equivalent input of energy.\\

As the English were taking full advantage of their engines driven by the heat energy from burning coal to run their business, their neighbors the French grew increasingly anxious. This prompted the brilliant military engineer Sadi Carnot from a learned French clan to carry out the first theoretical study of the principles behind the engines. His penetrating investigation completed by the time he was 27 more or less laid the foundations of thermodynamics. Subsequently, he suddenly went mad at the age of 36 and died from cholera shortly thereafter. Due to the contagious nature of the disease many of his works were buried with him but what survived was his famous work on the cycle of an engine. He recognized that for an engine to run it needed both a heat source from which it took heat to perform work and a heat sink at lower temperature than it to dump some of that heat that was not converted to work. While the source was rather obvious in the practical steam engines starting from those devised by James Watt, the sink was not -- it was merely the ambient surroundings in which the engine operated. Carnot went on to show the maximal efficiency an engine depended on the temperature of the source and the sink. Let $Q$ be the heat the engine takes from a source at (absolute) temperature $T_{so}$. Let $T_{si}$ be the temperature of the sink. Then the maximal work that can be done in a cycle of the engine is\\

 $W=Q\left(1-\dfrac{T_{si}}{T_{so}}\right)$\\
 
 This is the famous Carnot equation that indicates that not all heat can be effectively converted to work unless the source was at infinite temperature or the sink at absolute zero, neither of which are feasible options.\\
 
It is this inability to get all the heat to perform work which poses an additional constraint that negates even a lower form of perpetual motion machine, namely one which conserves energy but at least keeps running forever by cyclically converting one form energy into another. Two noted scientists of the age, Lord Kelvin and Rudolf Clausius (second in line from Gauss via Dirichlet with whom he studied mathematics) formalized Carnot’s discovery by the middle of the 1800s as a law:\\
\textit{“No cycle in which heat is taken from a hot source and converted completely into work is possible”} -Lord Kelvin\\
\textit{“Heat does not flow from a body at low temperature to one at high temperature without an accompanying change elsewhere.”} -Rudolf Clausius\\

These became the basic statements of the second law of thermodynamics. Clausius furthered this to define an entity termed entropy. He defined this such that the change in entropy multiplied by temperature specified that portion of heat which could not be converted to work. This led him to state the second law in a rather different way but ultimately entirely equivalent to the above statements:\\
\textit{The entropy of the universe increases during of any spontaneous change.}\\
Here a spontaneous change is one that occurs automatically, i.e. without needing any external work to be done for it to happen, e.g.: 1) when a compressed gas is released into an empty container of larger volume it \textit{spontaneously} expands to occupy that volume. 2) A hot metal piece placed at room temperature cools to the same temperature.\\

This statement of the second law provided a deeper insight into the nature of entropy. For instance, let us consider the above example of the gas expansion: the gas occupying a smaller volume of is more ordered. This can be expressed in probabilistic sense: The probability of find a gas molecule in a given unit of volume is higher in this state than when it spontaneously expands on being released into a larger empty container. Here the gas molecule moves over a larger space and the probability of finding the molecule in same unit volume decreases. Thus, the gas gets more disordered. Thus, entropy can be seen as a measure of disorder and the second law stated as: \textit{“matter and/or energy tend to get more disordered.”} The formal description of this idea had its roots in a discovery of the great James Clerk Maxwell in a distinct investigation, namely the function describing the distribution of the velocities of molecules in an ideal gas, again interestingly published in 1859 CE. In course of developing this abstraction further Boltzmann formulated his celebrated formula for the absolute entropy of a substance in 1877 (in the modern form given by Max Planck):\\
  $S=k_B\log(W)$\\
Here, $k_B$ is Boltzmann’s constant in energy and inverse temperature units and $W$ is the total number of ways in which atoms, molecules or energy elements can be arranged in the sample such that the total energy remains constant. Each such arrangement that fulfills this condition is termed a “microstate”.  Thus, $W$ is the total number of microstates in the sample. This simple formulation has profound implications for it allows one to connect the entropy of a sample to the probability of occurrence of each of the arrangements of the “atomic” entities in the sample: \\

  $S=-k_B \displaystyle \sum_i p_i \log(p_i)$\\

Here $p_i$ the probability with which microstate $m_i$ occurs in the sample.\\

While this is a thermodynamic concept, one can now extend it to be the general measure of disorder of any system. This can be illustrated with an often used example: say, on a national day we have large assembly of people. First, consider state-1: When the national anthem is being recited they all stand up in an erect posture and recite the same. Next state-2: once the anthem is over they might adopt a range of different postures with various conversations between individuals or small groups. Thus for a beholder of this system in state-1 the population is ordered and the information coming out from them is clearly perceived and limited (just the national anthem). In state-2, the population is disordered and information coming out from them is not easily perceived as it has a high degree of complexity being the sum of all the many individual conversations taking place. Thus, the abstract generalization of the thermodynamic entropy concept not only gives a general measure of disorder but also the information content of a system. It was this key generalization that Claude Shannon arrived at almost 70 years after Boltzmann’s initial discovery. His historic formula to quantify information essentially took the same form as Boltzmann’s formulation of thermodynamic entropy, just that Shannon’s is a pure number:\\

 $H=-\displaystyle \sum_i p_i \log_2(p_i)$\\

Here $p_i$ is the probability of the symbol $s_i$ in a certain symbol set occurring in the string $S$. Thus, Shannon entropy specifies the minimal number of bits per symbol needed to encode the string $S$ in binary form. Hence, $H$ also measures the complexity of a string $S$. As an example let us consider the following strings in the ASCII symbol set:\\
 $S_1=$ rAma rAma hare hare; $H(S_1)=2.7345$\\
 $S_2=$ ugram indraM juhomi; $H(S_2)=3.6163$ \\
One notes that $S_2$ has higher Shannon entropy than $S_2$ and provides quantitative evidence for the intuitive idea that the second string is more complex than the first. This remarkable link between the mathematical formulations of two rather disparate entities, one a description of very palpable quantities like matter and energy and the other an abstract quantity, information, can be summarized by quoting Shannon:\\

\textit{“Quantities of the form $H=-\sum p_i \log_2(p_i)$ (the constant $k_B$ merely amounts to a choice of a unit of measure) play a central role in information theory as measures of information, choice and uncertainty. The form of $H$ will be recognized as that of entropy as defined in certain formulations of statistical mechanics, where $p_i$ is the probability of a system being in cell $i$ of its phase space.”}\\

Shannon’s formulation of entropy as a measure of information has profound implications for understanding the foundations of life. This aspect has been of great importance in our own investigations and will touched upon in the final section. Before heading there we may ask if there is a deeper link between the thermodynamic and informational conceptions of entropy? That is a question which remains more mysterious. However, in that regard we will mere quote a noted scientist of our age, Murray Gell-Mann:\\

\textit{“In fact, entropy can be regarded as a measure of ignorance. When it is known only that a system is in a given macrostate [gross state of matter and energy in the sample], the entropy of the macrostate measures the degree of ignorance about which the microstate system is in, counting the number of bits of additional information needed to specify it, with all the microstates in the macrostate treated as equally probable.”}\\

We will conclude this section by merely mentioning some even more mysterious issues pertaining to the two laws of thermodynamics. Emmy Noether, probably greatest female mathematician of all times, proved a remarkable theorem now known as Noether’s theorem. A basic version of this theorem can be relatively easily understood by someone with junior college mathematics. However, in its more complete forms it extends into rarefied heights of mathematics. This basic version depends on the Lagrangian formulation of another great mathematician Joseph-Louis Lagrange to describe a physical system. Simply put the the Lagrangian of a system $L$ is the difference between its kinetic energy $T$ (not to confuse the symbol with temperature) and potential energy $U$:\\
 $L=T-U$\\
 
The Lagrangian $L$ is typically expressed as a function of the position $x$ of a body in the system and its time derivative, i.e. velocity $v=\tfrac{dx}{dt}$. As a simple example consider the Newtonian system of a body of mass $m$ raised to some height dropping under a uniform gravitation field with acceleration $g$. It would have kinetic energy $T=\tfrac{1}{2}m \cdot v^2$ and potential energy as $m\cdot g \cdot x$. Thus its Lagrangian can be written as:\\

  $L(x,v)=T-U=\tfrac{1}{2}m \cdot v^2-m\cdot g \cdot x$\\

Now, according to Noether’s theorem if $L(x,v)$ of a physical system remains unaffected upon transformation in the coordinate system used to describe it, i.e. symmetric under the transformation, then there will be a corresponding conservation law. Now, if a physical system is translated linearly to a different position and there is no other physical influence acting on it, its  $L(x,v)$ remains unaffected. This implies that the translational coordinate system is a uniform; thus, translational symmetry of the Lagrangian gives us the law of conservation of momentum. Similarly, that $L(x,v)$ is unaffected if the system is translated in time gives us the law of conservation of energy or the first law of thermodynamics. Thus, remarkably conservation of energy is related to time symmetry, i.e. time being an orderly or uniform coordinate system -- time does not flow fast and slow at different points along its flow. If that were to happen then energy would not be conserved.\\

Most physical laws are agnostic to flipping the time coordinate system, i.e. time reversal. For example, if we flipped time on the flight of an arrow from release to fall, there will be no changes to the laws of motion describing it. Similarly, if the time axis were flipped there would be no difference to the laws describing the revolution of planet around its star or the current in a circuit. As per Noether’s theorem if the Lagrangian of a system were unaffected under time-reversal then entropy would be conserved. But this is not so because it violates the second law of thermodynamics. So  it is the one physical law that has an inbuilt time direction. The measurement of entropy gives us the “arrow of time” to use Eddington’s term. The young universe was very hot a narrow energy range with energy and matter uniformly distributed. This was a low entropy state. With time the energy and matter become less uniformly distributed with clumping to form galaxies and their constituent star systems. Thus, the increasing entropy resulted in a complexity (if viewed in terms of information) of its structure. Thus, the state of the universe as described by its increasing entropy and hence information might be seen as reflection of the “unfolding” along the arrow of time.

\section{Laws for life}












\end{document}